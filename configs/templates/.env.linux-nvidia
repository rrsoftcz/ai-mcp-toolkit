# AI MCP Toolkit - Linux NVIDIA Configuration
# Optimized for NVIDIA GPU acceleration

# ============================================
# Server Configuration
# ============================================
MCP_HOST=localhost
MCP_PORT=8000

# ============================================
# Ollama Configuration (NVIDIA Optimized)
# ============================================
OLLAMA_HOST=localhost
OLLAMA_PORT=11434
OLLAMA_MODEL=qwen2.5:7b
# NVIDIA GPU settings
OLLAMA_GPU_LAYERS=-1
OLLAMA_NUM_GPU=1

# ============================================
# Web UI Configuration  
# ============================================
UI_HOST=localhost
UI_PORT=5173

# ============================================
# Performance Configuration (NVIDIA)
# ============================================
MAX_TEXT_LENGTH=200000
CHUNK_SIZE=2000
TEMPERATURE=0.1
MAX_TOKENS=4000

# ============================================
# GPU-Specific Settings
# ============================================
ENABLE_GPU_ACCELERATION=true
GPU_MEMORY_FRACTION=0.9
CUDA_VISIBLE_DEVICES=0

# ============================================
# Data Directories
# ============================================
DATA_DIR=~/.ai-mcp-toolkit
CACHE_DIR=~/.ai-mcp-toolkit/cache
MODELS_DIR=~/.ai-mcp-toolkit/models

# ============================================
# Development Configuration
# ============================================
LOG_LEVEL=INFO
ENABLE_CACHE=true
CACHE_TTL=3600
